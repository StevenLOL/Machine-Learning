\documentclass[oneside]{ZJUthesis}
\usepackage{longtable}
\hypersetup{colorlinks=false}
\begin{document}
\songti
\title{稀疏惩罚因子对无监督学习算法}
\titletl{的自动编码器的研究分析}
\author{姜楠}
\supervisor{龙胜春~副教授}
\major{计算机科学与技术+自动化1101}
\institute{计算机科学与技术学院}
\submitdate{2015年~6月}
\makeCoverPage
\ZJUfrontmatter
\begin{abstract}
机器学习算法严重依赖于数据的表示形式，支配着实验中的准确率。自动编码器算法模型架构用来从数据中学到的优良的数据表示形式，并且尽可能减少数据的失真。此外，该算法能有效提升数据的稀疏性，进而显著提高其在分类任务中的精确率，而且有助于解释特征向量。为了使自动编码器获得有效的稀疏特征，一种简单的方法就是在模型的代价函数中添加稀疏惩罚项。然而，在科技文献中，很少有评价稀疏惩罚项的优劣的实验研究。在本文中，我们采用L1范数、L2范数、Student-t惩罚因子和KL差分因子。接着，我们对这些惩罚因子按照实验评价标准：重构误差、特征的稀疏度和测试集上正确率来分析他们的功能优劣。实验数据集包括:MNIST、CIFAR-10、SVHN、OPTDIGITS和NORB五个数据集。实验结果表明这些惩罚因子均能产生稀疏特征，优于不添加任何惩罚因子的自动编码器。同时，我们也希望关于此主题的讨论研究能为今后的研究提供一些有用的思路。


\keywords{自动编码器，稀疏惩罚因子，稀疏编码，非监督学习}
\end{abstract}

\begin{Eabstract}
Machine learning algorithms depend heavily on the data representation, which dominates its success in experiment accuracy. Autoencoder model structure is proposed to learn from data a good representation with the least possible amount of distortion. Furthermore, it has been proven that boosting sparsity when learning representation can significantly improve performance on classification tasks and also make the feature vector easy to interpret. One straightforward approach for autoencoder to obtain sparse representation is to impose sparse penalty on its overall cost function. Nevertheless, few comparative analysis has been conducted to evaluate which sparse penalty term works better. In this paper, we adopt L1 norm, L2 norm, Student-t penalties, which are rarely deployed to penalise the hidden unit outputs, and commonly used penalty KL-divergence in the literature. Then, we present a detailed analysis to evaluate which penalty achieves better result in terms of reconstruction error, sparseness of representation and classification performance on test datasets. Experimental study on MNIST, CIFAR-10, SVHN, OPTDIGITS and NORB datasets reveals that all these penalties achieve sparse representation and outperforms representations learned by pure autoencoder on classification performance and sparseness of feature vectors. Moreover, we hope this topics and the practices would provide insights for future research.



\Ekeywords{autoencoder, sparse penalty, sparse coding, unsupervised feature learning}

\end{Eabstract}
\ZJUcontents
\ZJUListofFigures
\ZJUListofTables

\mainmatter
\chapter{绪论}
\section{研究背景}
监督学习（supervised learning）在许多领域有很成功的应用，如车牌识别、人脸识别、语音识别、自动驾驶等。尽管如此，监督学习还是有很大的限制。因为监督学习需要手工的选择特征来训练算法。提取的特征质量直接影响到机器学习算法的性能。虽然很多权威学者针对特定的应用提出了很多有效的特征，但这些算法技巧不具有推广的意义。BP神经网络模型由输入层、隐藏层、输出层构成，是监督学习算法中的一个广泛使用的模型。通过求解误差的偏导，并利用反向传导公式迭代求解出系统的极值，从而学习出数据集中的`` 合理规则''。特别地，他能突破传统多项式公式有限的拟合数据的能力，能学习到更加复杂的非线性函数规律和即使数据中包含一些误差，他也能收敛致最优解，拥有较强的自适应性。然而，由于BP神经网络的代价函数不是严格意义上的凸函数，一旦算法在迭代优化过程中陷入局部极值，就有可能无法求得系统的最优解。若要拟合高维复杂的函数，采用较复杂的神经网络模型就会导致函数运算量巨大、收敛过慢，若采用较小的神经网络模型，则只能学习到简单的函数方程，可能会忽略了重要的信息特征\cite{1}。

然而在实际应用中，我们无法预先知道样本的标签，只能从原始的无标签的样本集开始，进行分类器的设计，即通常所说的无监督学习方法（unsupervised learning）。无监督学习方法可以分类两类，一类为基于概率密度函数估计的方法，它试图找出数据集在特征空间的分布参数，再用特征空间分布进行分类处理，例如稀疏编码算法。另一类称为基于样本间的相似性度量的聚类方法，它通过聚类方法将样本划分成不同类别。 稀疏编码算法是第一类无监督算法的重要实践，它将原始信号表示为字典元素的一个线性组合：$x=D*a$，我们用 $x$ 表示原始信号， $D$ 为我们得到的字典（dictionary），通过字典 $D$ ， 原始信号 $x$ 能被完备地表示为 $a$ 的线性组合。当我们将稀疏性概念引入后，即我们希望 $a$ 是稀疏的，只有较少的非零项，这样做最突出的优点是运算速度能有效提升，因为Matlab只对非零元素进行操作。另一方面，为了解决字典 $D$ 的退化（degeneracy）问题，Hinton等人提出了稀疏自编码（Sparse Auto-encoder）学习算法。稀疏自编码算法是一种自动提取样本（如图像）特征的方法，它把原始数据用隐藏层的特征空间向量表示，再把隐藏层特征解码成重构的输出层。这样，隐藏层中的特征信息就是输入层的一个压缩表示，而且有效减少了冗余信息。并且，压缩表示的特征很适合进一步用作分类器的输入集。该模型可以用来标注无标签的数据集，免去了繁复的人工打标签的操作，同时也能有效降低输入数据的维度，防止出现``维度灾难''。

\section{研究问题的提出}
\subsection{研究内容}
基于稀疏理论的自动编码器是目前应用最为广泛的自动编码器，他能在低维的特征空间内重建高维数据变量，并获得稀疏表示的特征。获得的能用于后续的分类器，能有效增强数据的线性可分性，提高了分类器的准确率。本课题的研究目标定位于利用Matlab技术来实现自学习算法（稀疏自动编码器+Softmax回归模型），着重于讨论并研究稀疏自动编码器中的稀疏惩罚因子（Sparsity Penalty）对该自学习算法的性能表现，我们主要按照三个指标来评价其性能差异：提取的特征的稀疏度，测试集上的重构误差，测试集上的精确度。通过研讨其在不同数据集上的性能表现，期望分析出稀疏惩罚因子的实用价值及效用。

\subsection{研究目标}
\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{./Pictures/framework.eps}
\caption{实验研究的基本框架\label{fig:framework}}
\end{figure}

实验框架如图\ref{fig:framework}所示，主要由4个部分组成：数据预处理、稀疏自编码器训练、Softmax回归模型训练、统计计算实验指标。下面将详细解释了各个部分的具体内容。

\textbullet~\textbf{数据预处理：}数据预处理中，标准的第一步是数据归一化。特征归一化常用的方法包含如下几种：简单缩放、逐样本均值消减、特征标准化(使数据集中所有特征都具有零均值和单位方差)。

(1) \textbf{简单缩放：}我们通过简单缩放来重新调节各个维度的值域，使得最终的数据向量落在 [0,1]或[-1,1] 的区间内（根据数据情况而定）。针对图像，我们将像素在 [0,255] 区间除以 255，使它们缩放到 [0,1] 中.

(2) \textbf{逐样本均值消减：}如果数据是平稳的（即数据每一个维度的统计都服从相同分布），那么可以考虑在每个样本上减去数据的统计平均值(逐样本计算)。

(3) \textbf{特征标准化：}数据项减去其均值，再除以其方差，使得每一个维度具有零均值和单位方差，称为特征标准化。

\textbullet~ \textbf{稀疏惩罚因子的种类：}本实验拟采用机器学习中常用的惩罚因子：L1范数和L2范数，还有统计学中常用的数学模型：student-t分布模型，最后是稀疏自编码模型中常用的惩罚因子：KL距离（Kullback-Leibler divergence），作为主要的惩罚因子类别，并讨论分析其在实验中的性能表现。

\textbullet~ \textbf{稀疏自编码器训练：}自动编码器是一种无监督学习算法中的一种非线性网络结构，他能从无标签输入数据中提取出有效的特征信息，并能作为其他的深度学习网络架构的特征输入\cite{16}。自动编码器包含编码过程和解码过程。在编码过程中，我们将数据输入层$x$映射到隐含层特征$h$.在解码过程中，我们将隐含层特征$h$映射会重构的输入层$\hat x$。训练自动编码器的过程是在训练样本集D上寻找$\theta=\{W,b_y,b_h\}$ 的最小化重构误，一般可用平方误差函数或交叉熵损失函数。通过对原型自动编码器添加隐含层的约束，我们能获得稀疏表示的特征。我们拟采用神经网络中的梯度下降算法来训练稀疏自动编码器。	

\textbullet~ \textbf{Softmax回归模型训练：}传统的logistic回归模型只能适用于二元分类模型，类标签$y$只能取两个值（$y=\{0,1\}$），无法解决多元分类问题。在原有基础上，推导出的Softmax回归模型能解决多元分类问题，类标签$y$能选择多个值（$y=\{0,1,\cdots,n\}$）。Softmax回归模型能有效识别手写数字分类问题，例如MNIST数据集上的数字识别问题，辨识10个不同的单个数字。我们也来用梯度下降算法来训练Softmax回归模型$J(\theta;\lambda)$，但在训练该模型的同时，我们还需要通过K层交叉验证手段配置合适的超参数$\lambda$，以获得最优的模型参数配置。

\textbullet~ \textbf{统计计算实验指标：}当我们利用训练数据集完成了稀疏自编码器和Softmax回归模型的训练后，我们将采用测试数据集，按顺序输入稀疏自编码器和Softmax回归模型，与此同时我们需要统计：稀疏自编码器中获得的特征稀疏度、稀疏自编码器在测试集上的平均重构误差、Softmax模型的识别准确率。我们拟采用五个图像数据集，分别输入模型，再收集不同数据集上的数据后，分析其性能表现。

\section{研究意义}
\section{研究思路与研究方法}
\subsection{研究思路}
\subsection{研究方法}
\section{论文框架}
本论文大致分为几个部分，分别是绪论、相关研究及文献分析、系统设计、系统实现、研究结论与未来研究五个部分。

第一章绪论主要介绍了在系统分析之前的准备工作，包括研究背景、研究问题的提出、研究意义、研究思路与研究方法等；

第二章文献分析主要介绍了对自动编码器的国内外研究内容，算法模型和文献综述等；

第三章系统设计章节主要介绍了系统web端框架设计和后台Matlab算法模型架构设计，以及二者之间的接口设计；

第四章主要介绍了开发环境配置，界面设计、程序编码等；

最后一章主要对研究内容、研究创新点进行了总结，并分析了本次毕业设计存在的不足点和今后的研究展望等。

\chapter{相关研究及文献分析}
\section{国内外相关研究介绍}
\section{文献综述}

简洁的自动编码器模型在运用到实际条件中，演变产生各种修正的模型，按照其主要类别，大致分为：稀疏自动编码器、降噪自动编码器、鲁棒自动编码器和卷积自动编码器。

对稀疏性的兴趣源自于新的抽样理论-压缩传感（compressed sensing）的发展，当我们用压缩形式表示输入信号，我们能更方便的对信号进行加工处理，如压缩、编码等。通过对原型自动编码器的隐藏层添加约束条件，并增加隐藏层节点个数，我们能在隐藏层中获得原始数据的结构性特征。假设自定编码器的输入为$x$，我们的约束项为$\rho$，隐藏层神经元节点的平均激活度记作$\rho_j$。一般地，我们期望我们隐藏层的绝大多数神经元的取值在0 附近，少数神经元节点取值接近1，即只有少数神经节点处于激活状态。稀疏自动编码器能提取高位数据中的稀疏性特征，增加数据的线性可分性。然而原始数据分布规律不同，故我们需要较大的数据集来训练稀疏自动编码器以便完成的获取稀疏特征变量。另外我们需要预先调节KL散度的惩罚值，并要求隐藏层的平均激活程度相同，致使实验的效果较差，容易出现欠拟合问题。


降噪自动编码器（Denoising Auto-encoder）是在自动编码器的输入层中加入高斯分布的随机噪声，进而自动编码器在训练过程中，尝试学习去除这种噪声，解码过程中，模型根据噪声统计特性，从未受到干扰的数据中，估计出原始数据的分布规律，从而消除添加的高斯噪声。最终，自动编码器学习到的特征具有更强的鲁棒性，拥有更强的泛化能力\cite{28}。

当我们添加Frobenius范数作为惩罚因子后，收缩自动编码器能有效处理输入数据中的小扰动，而且隐藏层重构特征不受惩罚因子约束，有效提高了数据表示的鲁棒特性。我们可以利用BP算法求解系统的最优解，获得系统的最佳配置参数\cite{32}。

在计算机图像处理领域，卷积自动编码器能有效解决图像中存在的池化和白化问题。上述讨论的模型在应用到图形图像领域后，需要配置大量冗余的参数，计算效率也大大降低。然而卷积自动编码器能获取局部特征，完整保留边缘特征。



\section{理论基础}

\section{关键技术}
本应用设计过程中主要采用Django网络开发框架，以及后台的Matlab算法实现框架；

(1) \textbf{系统平台：}CentOS 6，Intel Xeon 24核，64GB内存。CentOS\footnote{CentOS: www.centos.org}是企业级社区操作系统，它是Linux的重要的一个发型系列产品。一直以来，由红帽公司负责维护，开发其更新和修复主要的功能缺陷。 当年，红帽公司本着开源的精神毅然将其开发的著名操作系统RHEL中的稳定的软件代码公开，并建立开发者社区来维护和更新其CentOS的系统架构。考虑到RHEL和CentOS拥有同样的源代码，因此有些企业针对部分服务器安装CentOS操作系统以替代昂贵的商业版的RHEL，CentOS的稳定的网络框架秉承RHEL操作系统的特点能满足苛刻的实践应用。RHEL和CentOS操作系统的主要不同点在，于CentOS并不包含RHEL开发的闭源代码库。CentOS对部分源代码进行修改，以便维护商家版权，减少不必要的纷争。

(2) \textbf{编程语言：}Matlab Script，Java JDK支持。在配置Matlab之前，需要配置Sun Java JDK\footnote{Java Development Kits: www.oracle.com}开发环境。由于Linux/Unix操作系统默认配置open JDK作为替代Sun Java JDK的java开发包，这在通用依赖java的软件中尚未构成问题。然而例如Matlab，Eclipse，Hadoop等软件必须依赖Sun Java JDK开发包和Sun Java JRE开发环境，故需要配置linux下Sun Java开发环境，以便后续步骤顺利进行。采用Matlab\footnote{Matlab: cn.mathworks.com}作为主要开发工具，主要基于以下几点考虑：
		
\textbf{(a) 编程环境：}本次实验不考虑使用集成的Matlab Simulink神经网络工具箱，转而独立使用matlab脚本语言实现算法框架。Maltab软件提供成熟的矩阵运算和丰富的科学计算函数库，极大方便了数学公式的代码实现。与此同时，Matlab针对矩阵运算进行了精密地优化，能并行地计算矩阵间的操作。Matlab的MEX编译器能支持C++，FORTRAN等语言的混合编译，部分对性能要求严格的函数转而利用C语言实现，能在硬件环境下更高效的执行。在分布式计算、大数据等潮流大行其道的今天，Matlab也提供了自身的分布式计算框架：Matlab Distributed Computing Engine（ 分布式计算引擎）的服务，它能利用计算集群来完成高负载的计算任务。在数据可视化方面，Matlab能利用脚本语言直接操作函数图像的绘制，并对其进行标注、打印。相较于跨平台的开源软甲 GNU Octave，matlab能提供更丰富的程序接口和系统计算库，故二者只兼容常见的函数，在许多特殊的地方各异。

(3) \textbf{前台设计：}为了展示实验结果，同时便于实验配置与操作，故设计了基于django架构\footnote{Django: www.djangoproject.com}的实验配置平台。该平台主要完成实验计算任务提交，实验数据结果展示功能和实验进度显示功能。由于针对部分较大的实验数据集，训练时间需要数百小时，若简单的采用matlab软件的GUI图形界面会导致界面卡死，长时间不响应等现象，无法满足人机交互准则。在计算任务提交环节，需要用户提交实验训练集和实验测试集，并自行指定数据预处理方法。由于针对不同数据源，数据预处理的优良对实验结果影响非常大，故采用单一的无法满足实验要求，故平台给出一系列预处理方法以供用户选择。实验数据结果展示页面主要展示matlab实验保存的实验图表，平台按照任务分类展示在界面上，用户也可以下载压缩实验数据图表资源，以供用户分析实验数据。实验进度显示界面主要展示不同任务的运行情况，以及当前系统的CPU，内存占用情况。

另一方面，考虑到界面设计的美观大方，采用时下流行的 Bootstrap 技术，选取 BeyondAdmin 模板作为Django框架的网页开发的静态模板。在静态模板中添加django框架的动态编程语言，完成系统所需的功能需求。

(4) \textbf{接口设计：}由于Matlab R2014b之后提供了python开发engine，故能在django框架中设计matlab开发接口，同时matlab算法模型开放数据输入和结果输出接口，以功能模块形式加载入系统中。


\section{本章小结}




\chapter{系统设计}
\section{Django框架简介}
\section{Bootstrap框架介绍}
\section{开发环境}
\subsection{服务器端环境要求}
\subsection{客户端环境要求}
\section{主要开发语言}
\section{本章小结}



\chapter{项目中期检查系统设计}

\section{系统功能模块设计}
\section{本章小结}


\chapter{项目中期检查系统实现}
\section{系统界面实现}
\section{系统框架整合实现}
\section{系统功能模块实现}
\section{本章小结}




\chapter{总结}
\section{完成的工作}
在本次毕业设计中，主要搭建了django网站，以便用户提交实验计算任务，查看任务进度和分析实验结果。同时开放实验预处理环节，以供用户自行抉择。后台采用matlab计算框架实现，完成用户提交的实验计算需求，并将结果以图表形式输出到系统指定的目录下，由于matlab自带的图表绘制系统更为专业，同时可以定制代码，显示特定格式的图表。所以相对于采用Web框架中的JS插件，利用实验数据结果绘制美观的图表，采用matlab的plot函数更能满足科研需求。


\section{主要的创新点}
本次毕业设计研究的核心是使用matlab Script语言完成了Auto-encoder算法框架的实现，其次采用时下流行的web技术搭建人机交互平台，便于实验人员的操作与维护。

\section{存在的问题及下一步工作}
经过四年的本科学习，我初步掌握了计算机的专业知识和基本技能，在最后一学期的实践环节中，经过几个月的设计与实现，基本完成了前台的WEB界面框架和后台的MATLAB算法框架。其功能基本符合用户需求，能后完成用户在线提交计算任务，自动完成任务计算，并展示任务结果等功能。由于毕业设计时间较短，网站框架掌握不全，所以该应用还有许多不尽如人意的地方，如：。今后的网站应用将进一步优化完善前台界面和后台对应功能支持，以保证能解构更多的计算任务需求，以更好地为用户提供计算服务。

\backmatter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ZJUthesisbib{thesisbib}

\begin{thanks}
~~~~~~~~毕业设计得以顺利完成，除了我自己一年来的潜心学习和研究之外，也凝聚了很多人的心血。所以在这里，我要对帮助我顺利完成毕业设计的所有人表示感谢。我要对我指导老师――龙胜春老师，表示我最由衷的感谢。本课题在选题及开发过程中得到龙老师的悉心指导。龙老师把关督促毕业设计的进展，并为指点，帮助我开拓研究思路，热忱鼓励。龙老师一丝不苟的作风，严谨求实的态度，踏踏实实的精神一直是我的榜样。另外还要感谢我的同伴和在实践中帮助过我的同学，使我能顺利完成毕业设计。感谢其他同学和老师，感谢浙江工业大学，在毕业设计开发过程中提供良好工作环境和气氛。
\end{thanks}


\appendix
\chapter{附录}
\textbf{附录1~ 毕业设计文献综述}

\textbf{附录2~ 毕业设计开题报告}

\textbf{附录3~ 毕业设计外文翻译（中文译文与外文原文）}


\ZJUindex


\end{document}

