\documentclass[oneside]{ZJUthesis}
\usepackage{longtable}
\hypersetup{colorlinks=false}
\begin{document}
\songti
\title{稀疏惩罚因子对无监督学习算法}
\titletl{的自动编码器的研究分析}
\author{姜楠}
\supervisor{龙胜春~副教授}
\major{计算机科学与技术+自动化1101}
\institute{计算机科学与技术学院}
\submitdate{2015年~6月}
\makeCoverPage
\ZJUfrontmatter
\begin{abstract}
机器学习算法严重依赖于数据的表示形式，支配着实验中的准确率。自动编码器算法模型架构用来从数据中学到的优良的数据表示形式，并且尽可能减少数据的失真。此外，该算法能有效提升数据的稀疏性，进而显著提高其在分类任务中的精确率，而且有助于解释特征向量。为了使自动编码器获得有效的稀疏特征，一种简单的方法就是在模型的代价函数中添加稀疏惩罚项。然而，在科技文献中，很少有评价稀疏惩罚项的优劣的实验研究。在本文中，我们采用L1范数、L2范数、Student-t惩罚因子和KL差分因子。接着，我们对这些惩罚因子按照实验评价标准：重构误差、特征的稀疏度和测试集上正确率来分析他们的功能优劣。实验数据集包括:MNIST、CIFAR-10、SVHN、OPTDIGITS和NORB五个数据集。实验结果表明这些惩罚因子均能产生稀疏特征，优于不添加任何惩罚因子的自动编码器。同时，我们也希望关于此主题的讨论研究能为今后的研究提供一些有用的思路。


\keywords{自动编码器，稀疏惩罚因子，稀疏编码，非监督学习}
\end{abstract}

\begin{Eabstract}
Machine learning algorithms depend heavily on the data representation, which dominates its success in experiment accuracy. Autoencoder model structure is proposed to learn from data a good representation with the least possible amount of distortion. Furthermore, it has been proven that boosting sparsity when learning representation can significantly improve performance on classification tasks and also make the feature vector easy to interpret. One straightforward approach for autoencoder to obtain sparse representation is to impose sparse penalty on its overall cost function. Nevertheless, few comparative analysis has been conducted to evaluate which sparse penalty term works better. In this paper, we adopt L1 norm, L2 norm, Student-t penalties, which are rarely deployed to penalise the hidden unit outputs, and commonly used penalty KL-divergence in the literature. Then, we present a detailed analysis to evaluate which penalty achieves better result in terms of reconstruction error, sparseness of representation and classification performance on test datasets. Experimental study on MNIST, CIFAR-10, SVHN, OPTDIGITS and NORB datasets reveals that all these penalties achieve sparse representation and outperforms representations learned by pure autoencoder on classification performance and sparseness of feature vectors. Moreover, we hope this topics and the practices would provide insights for future research.



\Ekeywords{autoencoder, sparse penalty, sparse coding, unsupervised feature learning}

\end{Eabstract}
\ZJUcontents
\ZJUListofFigures
\ZJUListofTables

\mainmatter
\chapter{绪论}
\section{选题背景与意义}
监督学习（supervised learning）在许多领域有很成功的应用，如车牌识别、人脸识别、语音识别、自动驾驶等。尽管如此，监督学习还是有很大的限制。因为监督学习需要手工的选择特征来训练算法。提取的特征质量直接影响到机器学习算法的性能。虽然很多权威学者针对特定的应用提出了很多有效的特征，但这些算法技巧不具有推广的意义。BP神经网络模型由输入层、隐藏层、输出层构成，是监督学习算法中的一个广泛使用的模型。通过求解误差的偏导，并利用反向传导公式迭代求解出系统的极值，从而学习出数据集中的`` 合理规则''。特别地，他能突破传统多项式公式有限的拟合数据的能力，能学习到更加复杂的非线性函数规律和即使数据中包含一些误差，他也能收敛致最优解，拥有较强的自适应性。然而，由于BP神经网络的代价函数不是严格意义上的凸函数，一旦算法在迭代优化过程中陷入局部极值，就有可能无法求得系统的最优解。若要拟合高维复杂的函数，采用较复杂的神经网络模型就会导致函数运算量巨大、收敛过慢，若采用较小的神经网络模型，则只能学习到简单的函数方程，可能会忽略了重要的信息特征\cite{1}。

然而在实际应用中，我们无法预先知道样本的标签，只能从原始的无标签的样本集开始，进行分类器的设计，即通常所说的无监督学习方法（unsupervised learning）。无监督学习方法可以分类两类，一类为基于概率密度函数估计的方法，它试图找出数据集在特征空间的分布参数，再用特征空间分布进行分类处理，例如稀疏编码算法。另一类称为基于样本间的相似性度量的聚类方法，它通过聚类方法将样本划分成不同类别。 稀疏编码算法是第一类无监督算法的重要实践，它将原始信号表示为字典元素的一个线性组合：$x=D*a$，我们用 $x$ 表示原始信号， $D$ 为我们得到的字典（dictionary），通过字典 $D$ ， 原始信号 $x$ 能被完备地表示为 $a$ 的线性组合。当我们将稀疏性概念引入后，即我们希望 $a$ 是稀疏的，只有较少的非零项，这样做最突出的优点是运算速度能有效提升，因为Matlab只对非零元素进行操作。另一方面，为了解决字典 $D$ 的退化（degeneracy）问题，Hinton等人提出了稀疏自编码（Sparse Auto-encoder）学习算法。稀疏自编码算法是一种自动提取样本（如图像）特征的方法，它把原始数据用隐藏层的特征空间向量表示，再把隐藏层特征解码成重构的输出层。这样，隐藏层中的特征信息就是输入层的一个压缩表示，而且有效减少了冗余信息。并且，压缩表示的特征很适合进一步用作分类器的输入集。该模型可以用来标注无标签的数据集，免去了繁复的人工打标签的操作，同时也能有效降低输入数据的维度，防止出现``维度灾难''。


\section{国内外研究现状}
简洁的自动编码器模型在运用到实际条件中，演变产生各种修正的模型，按照其主要类别，大致分为：稀疏自动编码器、降噪自动编码器、鲁棒自动编码器和卷积自动编码器。

\subsection{稀疏自动编码器}
对稀疏性的兴趣源自于新的抽样理论-压缩传感（compressed sensing）的发展，当我们用压缩形式表示输入信号，我们能更方便的对信号进行加工处理，如压缩、编码等。通过对原型自动编码器的隐藏层添加约束条件，并增加隐藏层节点个数，我们能在隐藏层中获得原始数据的结构性特征。假设自定编码器的输入为$x$，我们的约束项为$\rho$，隐藏层神经元节点的平均激活度记作$\rho_j$。一般地，我们期望我们隐藏层的绝大多数神经元的取值在0 附近，少数神经元节点取值接近1，即只有少数神经节点处于激活状态。稀疏自动编码器能提取高位数据中的稀疏性特征，增加数据的线性可分性。然而原始数据分布规律不同，故我们需要较大的数据集来训练稀疏自动编码器以便完成的获取稀疏特征变量。另外我们需要预先调节KL散度的惩罚值，并要求隐藏层的平均激活程度相同，致使实验的效果较差，容易出现欠拟合问题。

\subsection{降噪自动编码器}
降噪自动编码器（Denoising Auto-encoder）是在自动编码器的输入层中加入高斯分布的随机噪声，进而自动编码器在训练过程中，尝试学习去除这种噪声，解码过程中，模型根据噪声统计特性，从未受到干扰的数据中，估计出原始数据的分布规律，从而消除添加的高斯噪声。最终，自动编码器学习到的特征具有更强的鲁棒性，拥有更强的泛化能力\cite{28}。

\subsection{收缩自动编码器}
当我们添加Frobenius范数作为惩罚因子后，收缩自动编码器能有效处理输入数据中的小扰动，而且隐藏层重构特征不受惩罚因子约束，有效提高了数据表示的鲁棒特性。我们可以利用BP算法求解系统的最优解，获得系统的最佳配置参数\cite{32}。

\subsection{卷积自动编码器}
在计算机图像处理领域，卷积自动编码器能有效解决图像中存在的池化和白化问题。上述讨论的模型在应用到图形图像领域后，需要配置大量冗余的参数，计算效率也大大降低。然而卷积自动编码器能获取局部特征，完整保留边缘特征。

\section{需要解决的问题及研究内容}
\subsection{需要解决的问题}
1. 随着模型的架构变得巨大和神经元节点数量地增加，梯度弥散现象越来越严重，使得自动编码器无法拟合一些高维复杂函数\cite{35}。 另一方面，生物神经学科发展远远落后于深度学习发展速度，现有理论的突破需要神经科学的进一步研究成果\cite{36,37}。自动编码器的训练时间过长，系统调优需要很多设计技巧，且研究员尚无法认识学习到的特征的物理意义何在。另外，由于现有建模单元尚存在理论缺陷，简单堆叠搭建深度结构必然存在先天缺陷。目前的建模手段（堆叠、预训练、调优）相对单一，无法满足复杂网络训练需求\cite{40}。

2. 现有的预训练算法对类标签数据集有较强的依赖性，远没有达到``无监督学习''\cite{41}。不仅如此，现有算法对硬件需求极高，随着处理数据规模的增大，现有软硬件环境无法满足其需求。若能按照深度结构模型设计对应的硬件配置，那将革新现有的算法效率\cite{43}。

\subsection{研究内容}
1. 基于稀疏理论的自动编码器是目前应用最为广泛的自动编码器，他能在低维的特征空间内重建高维数据变量，并获得稀疏表示的特征。获得的能用于后续的分类器，能有效增强数据的线性可分性，提高了分类器的准确率。本课题的研究目标定位于利用Matlab技术来实现自学习算法（稀疏自动编码器+Softmax回归模型），着重于讨论并研究稀疏自动编码器中的稀疏惩罚因子（Sparsity Penalty）对该自学习算法的性能表现，我们主要按照三个指标来评价其性能差异：提取的特征的稀疏度，测试集上的重构误差，测试集上的精确度。通过研讨其在不同数据集上的性能表现，期望分析出稀疏惩罚因子的实用价值及效用。

2. 为了便于实验，搭建web实验平台，以网络服务形式开放给用户使用。其计算模型是稀疏自动编码器模型，用户可以在实验平台上提交实验的数据集，和实验的数据预处理手段，当用户自定义完上述选项后就可以以任务形式提交到实验平台上，网站后台接收到用户的计算请求后，调用硬件资源开始计算。用户可以实时查看计算任务的进展，当任务完成后，平台将实验的数据及实验图表展示给用户。用户可以在线查看实验结果，以进行后续数据分析。


\chapter{开发环境及框架介绍}
\section{系统开发环境}
现在有许多主流的操作系统，我们应当根据不同的使用需求，合理选择操作系统。例如为众人所熟知的Win7操作系统适用于家庭休闲使用，由于其病毒较多、不支持主流开发技术等原因，不适合选做系统开发环境。系统开发、网站建设通常采用较为稳定、高效的Linux系统。Linux开源系统中，又以CentOS作为主流的服务器的操作系统。本实验的环境配置为：CentOS 6 操作系统，Intel Xeon 24核 CPU，64GB内存。CentOS\footnote{CentOS: www.centos.org}是企业级社区操作系统，它是Linux的重要的一个发型系列产品。一直以来，由红帽公司负责维护，开发其更新和修复主要的功能缺陷。 当年，红帽公司本着开源的精神毅然将其开发的著名操作系统RHEL中的稳定的软件代码公开，并建立开发者社区来维护和更新其CentOS的系统架构。考虑到RHEL和CentOS拥有同样的源代码，因此有些企业针对部分服务器安装CentOS操作系统以替代昂贵的商业版的RHEL，CentOS的稳定的网络框架秉承RHEL操作系统的特点能满足苛刻的实践应用。RHEL和CentOS操作系统的主要不同点在，于CentOS并不包含RHEL开发的闭源代码库。CentOS对部分源代码进行修改，以便维护商家版权，减少不必要的纷争。

在此操作系统系统之上，安装matlab软件所依赖的Oracle JDK 8。同时本实验所采用的Django 开发框架依赖于Python 2.7和MySql 6。均需要预先安装。

\section{编程语言和编程环境的选择}
本实验采用Matlab Script\footnote{Matlab: cn.mathworks.com}作为算法模型的实现语言（需要Java JDK支持），采用Python2.7作为实验平台的开发语言，采用主流的Web框架django。主要基于以下考虑：matlab中配备丰富的矩阵运算接口，并且Matlab底层的矩阵运算均进行了并行优化处理。相对于Python的numpy开发库，matlab有更高效运算效率，采用Python脚本语言后台调用matlab 接口函数比采用纯粹的Python开发框架能有效增强平台的响应时间。另一方面，尽管Matlab配备了GUI开发框架，开发人员能直接拖拽组建搭建实验的界面，针对运算时间较短的程序采用Matlab GUI是一个很好的选择。然而，本算法的迭代求解最优参数环节耗时巨大，会导致界面长时间无法响应用户的交互需求，同时若采用异步线程维护GUI线程和后台运算线程，会造成不必要的CPU和内存的开销，故采用第三方语言实现平台界面的搭建，Django正是这样的敏捷开发的框架，能在较短的开发周期内实现用户的功能需求。

另外，本实验环境为CentOS操作系统，在配置Matlab之前，需要配置Oracle Java JDK\footnote{Java Development Kits: www.oracle.com}开发环境。由于Linux/Unix操作系统默认配置open JDK作为替代Sun Java JDK的java开发包，这在通用依赖java的软件中尚未构成问题。然而例如Matlab，Eclipse，Hadoop等软件必须依赖Sun Java JDK开发包和Sun Java JRE开发环境，故需要配置linux下Sun Java开发环境，以便后续步骤顺利进行。


尽管开源软件GNU Octave能提供与matlab同样的计算服务，而且开源软件Octave无需考虑版权、授权证书等商业软件Matlab的约束，但在许多特殊的数据处理细节上，两个各异程度较大，只能兼容常见的系统函数。另一方面，Maltab自带的数据可视化工具，能直接采用脚本语言操纵图像的绘制，并对图像进行必要的标注和打印，Matlab提供的MEX编译器能支持C++，python，Java等支流开发语言的混合编译，部分对性能要求严格的函数转而利用C语言实现，能在硬件环境下更高效的执行，通用性远远高于Octave软件。故放弃Octave软件，转而采用Matlab软件。

历来Python的IDE纷繁复杂，由于其环境配置简洁，就连通用的代码编辑器也支持Python的开发与编译。本次实验采用的Pycharm支持Django开发，同时支持git版本管理，相比于采用在终端下维护开发代码，Pycharm能减少许多不必要的时间浪费，尽管其对内存占用异常高。



\subsection{网站框架}
网站采用Django框架，它是一种符合MVC设计模式（即模型Model，视图View和控制器Controller）的新一代Web框架。它最初用来维护开发新闻内容的网站，并于2005年在BSD在许可证下发布，本实验平台开发采用最新版本Django 1.8。后台的支持数据库可以选用Mysql，SQLite，Oracle.本实验平台采用通用的Mysql 5.6版本，SQLite是基于文本的数据库过于简单，不宜用作网站持续运营。

Django框架的核心技术包括：面向对象的数据模型映射器；基于正则表达式的URL分发器；一个视图系统，用于处理网络请求；以及一个模板系统。

\subsection{GIT插件介绍}
由于开发实验平台和算法模型的时候需要进行代码备份与记录，所以需要外部的版本控制软件来维护实验代码，以防止异常的出现损坏实验的代码。git是常见的分布式版本控制软件，能跟踪记录软件开发过程中的迭代。本实验的代码均采用github.com提供的远程git服务器，每当进行算法修改之后，均将修改的代码记录上传至服务器，以作备份，一旦本地代码出现异常，可以使用远程的代码库恢复本地，减少不必要的损失。

Django的开发IDE Pycharm已经完善的集成了GIT版本控制插件，能直接commit 和Push代码至远程版本控制服务器。matlab R2014a中尚未完善支持git插件，故采用安装git软件来维护matlab的算法开发目录下的文件。






\section{本章小结}
这一张主要解释了该实验的开发环境的选取准则和项目的基本设计框架模型。

整个开发环境均采用主流的开发工具。如操作系统选用稳定的CentOS操作系统，集成开发环境选择Pycharm4 和Matlab R2014a，以及后续的服务器引擎Nginx。同时，也需要进一步时间来学习如何使用这些工具。

整个实验平台的基本框架采用MVC模式的Django，使得前台的界面和后台的功能实现能分离，松耦合度的结构能有效减少代码逻辑混乱造成的异常与错误。算法模型采用Maltab语言实现，并对其进行模块化处理，针对用户不同的实验需求，配备不同的实验算法模块。

为了维护开发过程中的项目软件，减少人为错误带来的灾难性后果，例如：无意间删除了部分代码文件，磁盘烧毁，系统宕机。通过git插件和github.com版本控制服务器，用户能方便的提交当前代码至远程服务器作为备份资料，最大程度的保障本地代码的完整性。


\chapter{算法数学模型介绍}
\section{原型自动编码器}
通过无监督学习训练，原型自动编码器能学习到数据中的非线性特征结构，他能提取出高位复杂的输入数据中的低维特征，将此特征用于深度学习其他模型的输入，能有效提升系统的精确度\cite{16}。

自动编码器模型包括编码和解码两个主要步骤。在编码阶段，编码器将输入数据 $x$ 映射到隐含层特征$h$，其映射函数为：
\begin{equation}
	h=f(Wx+b)
\end{equation}
其中，$f$被称为``激活函数''，一般为 $sigmoid$ 函数，其取值域为 $[0,1]$ ，其表达式为：
\begin{equation}
	f(x)=\frac{1}{1+e^{-x}}
\end{equation}
或者也可以是$tanh$函数，其取值域为 $[-1,1]$，其表达式为：
\begin{equation}
	f(x)=\frac{1-e^{-x}}{1+e^{-x}}
\end{equation}
这类函数糅合了线性和非线性特性函数，当 $x$ 较大时函数迅速收敛至值域的边界，当 $x$ 较小时函数是S型的非线性函数，相比于传统的阈值函数能更好的模拟神经元的工作原理。

在解码阶段，映射函数 $g(h)$ 将隐含层特征空间映射回重构的输入层$\hat x$ ，表示为：
\begin{equation}
	\hat x=g(\hat{W}h+\hat b)
\end{equation}	
其中， $g$ 是解码器的激活函数，若采用线性函数，则该解码器被称为``线性解码器''（Linear Decoder），若采用$sigmoid$ 函数，则是原型自动编码器采用的架构。在训练自动编码器的过程中，我们利用迭代求解当前状态的梯度值，最终求得在训练样本集 $D$ 上的一组最佳的参数配置 $\theta=\{W,\hat W,b,\hat b\}$ ，使系统的重构误差函数最小，重构误差函数的表达式为：
\begin{equation}
	J_{AE}=\sum_{x_i \in D}L(x_i,g(f(x_i)))
\end{equation}
其中， $L$ 为每个输入项 $x_i$ 的重构误差值，一般地，我们使用平方误差函数或者交叉熵损失函数表示，二者数学公式分别表示为：
\begin{equation}\begin{array}{l}
	L(x,y)=\sum_{x_i \in D}\|x-\hat x\|^2  \\
    L(x,y)=-\sum_{x_i \in D}[x_i \log \hat x_i+(1-x_i)\log(1-\hat x_i)]
\end{array}\end{equation}
其中，当我们采用$g$为线性函数时，系统的重构误差函数须采用平方误差函数。当我们采用$g$为 sigmoid函数时，系统的重构误差函数须采用交叉熵损失函数，这两者之间相互一一对应 \cite{17}。 图\ref{fig:origAE} 展示了原型自动编码器的结构。原型自动编码器包含输入层、隐藏层和输出层，其中编码过程对应于输入层到隐藏层的映射，解码过程对应于隐藏层到输出层的映射。

\begin{figure}
\centering
\includegraphics[scale=0.4]{./Pictures/origAE.eps}
\caption{原型自动编码器，它由输入层、隐藏层和输出层构成。}
\label{fig:origAE}
\end{figure}


\section{稀疏惩罚因子的种类}
对稀疏性的兴趣源自于新的抽样理论-压缩传感（compressed sensing）的发展，当我们用压缩形式表示输入信号，我们能更方便的对信号进行加工处理，如压缩、编码等。通过对原型自动编码器的隐藏层添加约束条件，并增加隐藏层节点个数，我们能在隐藏层中获得原始数据的结构性特征。假设自定编码器的输入为$x$，我们的约束项为$\rho$，隐藏层神经元节点的平均激活度记作$\rho_j$。一般地，我们期望我们隐藏层的绝大多数神经元的取值在0 附近，少数神经元节点取值接近1，即只有少数神经节点处于激活状态。我们期望$\rho$取值在0附近（例如，0.05），同时令$\frac{1}{m}\sum_j^m{\rho_j}=\rho$。在稀疏自动编码器中，我们在模型的代价函数中增加稀疏惩罚项$KL(\rho||\rho_j)$，其表达式为：
\begin{equation}
	KL(\rho||\rho_j)=\rho \log \frac{\rho}{\rho_j} + (1-\rho)\log \frac{1-\rho}{1-\rho_j}
\end{equation}
此时，系统的代价函数为：
\begin{equation}
	J_{SAE}(W,b)=J(W,b)+\beta \sum_{j=1}^{s_2}KL(\rho||\rho_j)
\end{equation}
其中，$J_{SAE}(W,b)$代表稀疏自动编码器的代价函数，$J(W,b)$代表原型自动编码器的代价函数，$\beta$表示稀疏惩罚项的权重，$s_2$代表隐藏层节点个数\cite{24}。

\subsection{KL差分因子}
\subsection{L1范数因子}
\subsection{L2范数因子}
\subsection{Student-t惩罚因子}


\section{Softmax预测器的模型架构}
\textbullet~ \textbf{Softmax回归模型训练：}传统的logistic回归模型只能适用于二元分类模型，类标签$y$只能取两个值（$y=\{0,1\}$），无法解决多元分类问题。在原有基础上，推导出的Softmax回归模型能解决多元分类问题，类标签$y$能选择多个值（$y=\{0,1,\cdots,n\}$）。Softmax回归模型能有效识别手写数字分类问题，例如MNIST数据集上的数字识别问题，辨识10个不同的单个数字。我们也来用梯度下降算法来训练Softmax回归模型$J(\theta;\lambda)$，但在训练该模型的同时，我们还需要通过K层交叉验证手段配置合适的超参数$\lambda$，以获得最优的模型参数配置。


\section{数据预处理操作}
\textbullet~\textbf{数据预处理：}数据预处理中，标准的第一步是数据归一化。特征归一化常用的方法包含如下几种：简单缩放、逐样本均值消减、特征标准化(使数据集中所有特征都具有零均值和单位方差)。

(1) \textbf{简单缩放：}我们通过简单缩放来重新调节各个维度的值域，使得最终的数据向量落在 [0,1]或[-1,1] 的区间内（根据数据情况而定）。针对图像，我们将像素在 [0,255] 区间除以 255，使它们缩放到 [0,1] 中.

(2) \textbf{逐样本均值消减：}如果数据是平稳的（即数据每一个维度的统计都服从相同分布），那么可以考虑在每个样本上减去数据的统计平均值(逐样本计算)。

(3) \textbf{特征标准化：}数据项减去其均值，再除以其方差，使得每一个维度具有零均值和单位方差，称为特征标准化。

\section{实验性能评价指标}
\textbullet~ \textbf{统计计算实验指标：}当我们利用训练数据集完成了稀疏自编码器和Softmax回归模型的训练后，我们将采用测试数据集，按顺序输入稀疏自编码器和Softmax回归模型，与此同时我们需要统计：稀疏自编码器中获得的特征稀疏度、稀疏自编码器在测试集上的平均重构误差、Softmax模型的识别准确率。我们拟采用五个图像数据集，分别输入模型，再收集不同数据集上的数据后，分析其性能表现。



(3) \textbf{前台设计：}为了展示实验结果，同时便于实验配置与操作，故设计了基于django架构\footnote{Django: www.djangoproject.com}的实验配置平台。该平台主要完成实验计算任务提交，实验数据结果展示功能和实验进度显示功能。由于针对部分较大的实验数据集，训练时间需要数百小时，若简单的采用matlab软件的GUI图形界面会导致界面卡死，长时间不响应等现象，无法满足人机交互准则。在计算任务提交环节，需要用户提交实验训练集和实验测试集，并自行指定数据预处理方法。由于针对不同数据源，数据预处理的优良对实验结果影响非常大，故采用单一的无法满足实验要求，故平台给出一系列预处理方法以供用户选择。实验数据结果展示页面主要展示matlab实验保存的实验图表，平台按照任务分类展示在界面上，用户也可以下载压缩实验数据图表资源，以供用户分析实验数据。实验进度显示界面主要展示不同任务的运行情况，以及当前系统的CPU，内存占用情况。

另一方面，考虑到界面设计的美观大方，采用时下流行的 Bootstrap 技术，选取 BeyondAdmin 模板作为Django框架的网页开发的静态模板。在静态模板中添加django框架的动态编程语言，完成系统所需的功能需求。

(4) \textbf{接口设计：}由于Matlab R2014b之后提供了python开发engine，故能在django框架中设计matlab开发接口，同时matlab算法模型开放数据输入和结果输出接口，以功能模块形式加载入系统中。



\subsection{研究目标}
\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{./Pictures/framework.eps}
\caption{实验研究的基本框架\label{fig:framework}}
\end{figure}

实验框架如图\ref{fig:framework}所示，主要由4个部分组成：数据预处理、稀疏自编码器训练、Softmax回归模型训练、统计计算实验指标。下面将详细解释了各个部分的具体内容。


\textbullet~ \textbf{稀疏惩罚因子的种类：}本实验拟采用机器学习中常用的惩罚因子：L1范数和L2范数，还有统计学中常用的数学模型：student-t分布模型，最后是稀疏自编码模型中常用的惩罚因子：KL距离（Kullback-Leibler divergence），作为主要的惩罚因子类别，并讨论分析其在实验中的性能表现。

\textbullet~ \textbf{稀疏自编码器训练：}自动编码器是一种无监督学习算法中的一种非线性网络结构，他能从无标签输入数据中提取出有效的特征信息，并能作为其他的深度学习网络架构的特征输入\cite{16}。自动编码器包含编码过程和解码过程。在编码过程中，我们将数据输入层$x$映射到隐含层特征$h$.在解码过程中，我们将隐含层特征$h$映射会重构的输入层$\hat x$。训练自动编码器的过程是在训练样本集D上寻找$\theta=\{W,b_y,b_h\}$ 的最小化重构误，一般可用平方误差函数或交叉熵损失函数。通过对原型自动编码器添加隐含层的约束，我们能获得稀疏表示的特征。我们拟采用神经网络中的梯度下降算法来训练稀疏自动编码器。	



\section{研究意义}
\section{研究思路与研究方法}
\subsection{研究思路}
\subsection{研究方法}
\section{论文框架}
本论文大致分为几个部分，分别是绪论、相关研究及文献分析、系统设计、系统实现、研究结论与未来研究五个部分。

第一章绪论主要介绍了在系统分析之前的准备工作，包括研究背景、研究问题的提出、研究意义、研究思路与研究方法等；

第二章文献分析主要介绍了对自动编码器的国内外研究内容，算法模型和文献综述等；

第三章系统设计章节主要介绍了系统web端框架设计和后台Matlab算法模型架构设计，以及二者之间的接口设计；

第四章主要介绍了开发环境配置，界面设计、程序编码等；

最后一章主要对研究内容、研究创新点进行了总结，并分析了本次毕业设计存在的不足点和今后的研究展望等。

\chapter{相关研究及文献分析}
\section{国内外相关研究介绍}
\section{文献综述}








\section{理论基础}

\section{关键技术}
本应用设计过程中主要采用Django网络开发框架，以及后台的Matlab算法实现框架；



\section{本章小结}




\chapter{系统设计}
\section{Django框架简介}
\section{Bootstrap框架介绍}
\section{开发环境}
\subsection{服务器端环境要求}
\subsection{客户端环境要求}
\section{主要开发语言}
\section{本章小结}



\chapter{项目中期检查系统设计}

\section{系统功能模块设计}
\section{本章小结}


\chapter{项目中期检查系统实现}
\section{系统界面实现}
\section{系统框架整合实现}
\section{系统功能模块实现}
\section{本章小结}




\chapter{总结}
\section{完成的工作}
在本次毕业设计中，主要搭建了django网站，以便用户提交实验计算任务，查看任务进度和分析实验结果。同时开放实验预处理环节，以供用户自行抉择。后台采用matlab计算框架实现，完成用户提交的实验计算需求，并将结果以图表形式输出到系统指定的目录下，由于matlab自带的图表绘制系统更为专业，同时可以定制代码，显示特定格式的图表。所以相对于采用Web框架中的JS插件，利用实验数据结果绘制美观的图表，采用matlab的plot函数更能满足科研需求。


\section{主要的创新点}
本次毕业设计研究的核心是使用matlab Script语言完成了Auto-encoder算法框架的实现，其次采用时下流行的web技术搭建人机交互平台，便于实验人员的操作与维护。

\section{存在的问题及下一步工作}
经过四年的本科学习，我初步掌握了计算机的专业知识和基本技能，在最后一学期的实践环节中，经过几个月的设计与实现，基本完成了前台的WEB界面框架和后台的MATLAB算法框架。其功能基本符合用户需求，能后完成用户在线提交计算任务，自动完成任务计算，并展示任务结果等功能。由于毕业设计时间较短，网站框架掌握不全，所以该应用还有许多不尽如人意的地方，如：。今后的网站应用将进一步优化完善前台界面和后台对应功能支持，以保证能解构更多的计算任务需求，以更好地为用户提供计算服务。

\backmatter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ZJUthesisbib{thesisbib}

\begin{thanks}
~~~~~~~~毕业设计得以顺利完成，除了我自己一年来的潜心学习和研究之外，也凝聚了很多人的心血。所以在这里，我要对帮助我顺利完成毕业设计的所有人表示感谢。我要对我指导老师――龙胜春老师，表示我最由衷的感谢。本课题在选题及开发过程中得到龙老师的悉心指导。龙老师把关督促毕业设计的进展，并为指点，帮助我开拓研究思路，热忱鼓励。龙老师一丝不苟的作风，严谨求实的态度，踏踏实实的精神一直是我的榜样。另外还要感谢我的同伴和在实践中帮助过我的同学，使我能顺利完成毕业设计。感谢其他同学和老师，感谢浙江工业大学，在毕业设计开发过程中提供良好工作环境和气氛。
\end{thanks}


\appendix
\chapter{附录}
\textbf{附录1~ 毕业设计文献综述}

\textbf{附录2~ 毕业设计开题报告}

\textbf{附录3~ 毕业设计外文翻译（中文译文与外文原文）}


\ZJUindex


\end{document}

