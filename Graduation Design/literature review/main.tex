\documentclass[oneside]{ZJUthesis}
\hypersetup{colorlinks=false}
\begin{document}
\songti
\title{自动编码器的研究与展望}
\author{姜楠}
\supervisor{龙胜春~副教授}
\major{计算机科学与技术+自动化1101}
\institute{计算机科学与技术学院}
\submitdate{2015年~2月}

\makeCoverPage

\mainmatter
\maketitle
\textbf{摘 要：}深度学习开创了机器学习领域发展的新纪元，它是神经网络模型的一个重要分支。自动编码器模型是深度学习领域中最重要的三大模型之一，他能完成非线性特征提取，是一种无监督学习算法，不需要标注的数据集。在本文中，我们首先阐述了自动编码器在历史发展中的演进，接下来我们介绍原型自动编码器的原理和架构，进而介绍它的训练学习特征的方法、步骤。然后，我们又介绍了自动编码器的变种，例如：稀疏自动编码器，卷积自动编码器。最后，我们探讨了自动编码器理论在实践中遇到的障碍，并分析了它的未来发展趋势。

\textbf{关键词：}{自动编码器~稀疏编码~无监督学习~神经网络}
\chapter{引言}
监督学习（supervised learning）在许多领域有很成功的应用，如车牌识别、人脸识别、语音识别、自动驾驶等。尽管如此，监督学习还是有很大的限制。因为监督学习需要手工的选择特征来训练算法。特征的好坏直接影响到学习算法的性能。虽然很多权威学者针对特定的应用提出了很多有效的特征，但对于其他应用，这些特征并不适用。BP神经网络模型由输入层、隐藏层、输出层构成，是监督学习算法中的一个广泛使用的模型。通过求解误差的偏导，并利用反向传导公式迭代求解出系统的极值，从而学习出数据集中的`` 合理规则''。特别地，他能突破传统多项式公式有限的拟合数据的能力，能学习到更加复杂的非线性函数规律和即使数据中包含一些误差，他也能收敛致最优解，拥有较强的自适应性。然而，由于BP神经网络的代价函数不是严格意义上的凸函数，一旦算法在迭代优化过程中陷入局部极值，就有可能无法求得系统的最优解。若要拟合高维复杂的函数，采用较复杂的神经网络模型就会导致函数运算量巨大、收敛过慢，若采用较小的神经网络模型，则只能学习到简单的函数方程，可能会忽略了重要的信息特征\cite{1}。

然而在实际应用中，我们无法预先知道样本的标签，只能从原始的无标签的样本集开始，进行分类器的设计，即通常所说的无监督学习方法（unsupervised learning）。无监督学习方法可以分类两类，一类为基于概率密度函数估计的方法，它试图找出数据集在特征空间的分布参数，再用特征空间分布进行分类处理，例如稀疏编码算法。另一类称为基于样本间的相似性度量的聚类方法，它通过聚类方法将样本划分成不同类别。 稀疏编码算法是第一类无监督算法的重要实践，它将原始信号表示为字典元素的一个线性组合：$x=D*a$，我们用 $x$ 表示原始信号， $D$ 为我们得到的字典（dictionary），通过字典 $D$ ， 原始信号 $x$ 能被完备地表示为 $a$ 的线性组合。当我们将稀疏性概念引入后，即我们希望 $a$ 是稀疏的，只有较少的非零项，这样做最突出的优点是运算速度能有效提升，因为Matlab只对非零元素进行操作。另一方面，为了解决字典 $D$ 的退化（degeneracy）问题，Hinton等人提出了稀疏自编码（Sparse Auto-encoder）学习算法。稀疏自编码算法是一种自动提取样本（如图像）特征的方法，它把输入层（如图像）用隐藏层的激活度表示，再把隐藏层信息重构成输出层。这样，隐藏层中的特征信息就是输入层的一个压缩表示，而且数据的信息熵也会相应地减小。并且，压缩表示的特征很适合进一步用作分类器的输入集。该模型可以用来标注无标签的数据集，免去了繁复的人工打标签的操作，同时也能有效降低输入数据的维度，防止出现``维度灾难''。

第一节介绍了自动编码器模型的历史发展过程，第二节介绍了原型自动编码器和后来演绎变形的各种自动编码器的数学模型和建模机理，包括：稀疏自动编码器、统计自动编码器、鲁棒自动编码器和卷积自动编码器。第三节，我们介绍常用的构建深度学习的开源库，最后我们分析了自动编码器目前在实践中遇到的问题，并进一步明确它的发展方向。


\chapter{自动编码器和稀疏编码的历史发展}
\begin{enumerate}
     \item 1959年，David Hubel等人\cite{44}在神经实验中，研究猫的视觉条纹皮层简单细胞，得出一个惊人的结论：主视皮层V1区神经元能将视觉信息转化为``稀疏表示''的特征，自此提出机器学习领域重要的``稀疏表示''的概念。
    \item 1972年，Barlow\cite{47}推导演绎出，自然环境的统计模型和稀疏性（Sparsity）必然存在某种联系，即稀疏表示可以体现出在大脑中的统计特征。
    \item 1986年，Rumelhart提出了自动编码器（Auto-encoder）的概念模型，并将此模型用于处理高维复杂数据，展示其模型的性能和优势\cite{3}。
    \item 1987年，Field等人\cite{48}提出，主视皮层V1 区细胞在学习视网膜的图像结构后能产生图像的稀疏表示。1989 年，D.J.Field等人\cite{50}提出了稀疏编码方法，它能使只有少数神经细胞响应任意的信号输入。
    \item 1997年，B.A.Olshausen和D.J.Field\cite{52} 按照集合的完备性的理论，提出了``超完备''的稀疏编码算法。
    \item 1997年，Bell和Sejnowski\cite{53}利用独立分量分析算法（Independent Component Analysis）分析自然图像，发现独立分量算法也能产生稀疏编码的特征。
    \item 2006年，Hinton和他的学生Ruslan Salakhutdinov\cite{2}修正了原型自动编码器的模型结构，并称其为深度自动编码器。先用无监督学习算法，逐层贪心训练单层的自动编码器，最后针对整个深度自动编码器，用反向传播算法进行系统的参数调优，这样的训练手段显著降低了神经网络的训练时间，同时也能有效防止传统反向传播方法极易陷入局部最优解的情况。
    \item 2007年，Benjio分层贪心训练受限玻尔兹曼机，再集中调优深度信念网络，取得了历史最佳的分类精度\cite{4}。
    \item 2008年，Vincent改进了自动编码器模型，在输入层添加高斯白噪声，获得了降噪自动编码器，它能有效降低系统的过拟合现象，具备更好的鲁棒性和良好的分类精度\cite{5}。
    \item 2009年，Benjio等人在文章``Learning Deep Architectures for AI''中总结了RBMs，SAE，CNN等已有的深度结构，并分析了在不同情况下的系统特性\cite{6}。
    \item 2010年，salah等人在文章``Contractive Auto-Encoders：Explicit Invariance During Feature Extraction'' 中，通过对系统的代价函数中添加Frobenius范数的惩罚因子，对自动编码器的解码和编码过程加以限制，提出了收缩自动编码器，获得了类似于降噪自动编码器、约束自动编码器的实验效果\cite{7}。
    \item 2011年，Lugano和Switzerland在文章``Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction''中，将卷积神经网络架构引入自动编码器模型，同时消去了不必要的约束惩罚项，利用其单层卷积自动编码器构建的深层卷积神经网络实现了在权威数据集上的突破性成果\cite{8}。
    \item 2012年，Pierre Baldi等人从数学角度，分析线性自动编码器并推导出非线性自动编码器。同时，也分析了自动编码器与无监督学习之间的联系\cite{9}。
    \item 2012年，Bengio等人比较了原型自动编码器、稀疏自动编码器、卷积自动编码器、收缩自动编码器、降噪自动编码器和限制玻尔兹曼机等结构的在不同参数配置和实验验数据集上的性能表现。\cite{10,11,12,13,14}。
    \item 2013年，Telmo Amaral在文章``Using Different Cost Functions to Train Stacked Auto-encoders'' 中，比较在训练过程中使用不同的代价函数，并评价分析这些代价函数对特征学习的影响，指出了优化代价函数的研究方向\cite{15}。
\end{enumerate}

\chapter{数学模型及数学原理}
\section{原型自动编码器的建模机理}
通过无监督学习训练，原型自动编码器能学习到数据中的非线性特征结构，他能提取出高位复杂的输入数据中的低维特征，将此特征用于深度学习其他模型的输入，能有效提升系统的精确度\cite{16}。

自动编码器模型包括编码和解码两个主要步骤。在编码阶段，编码器将输入数据 $x$ 映射到隐含层特征$h$，其映射函数为：
\begin{equation}
	h=f(Wx+b_n)
\end{equation}
其中，$f$被称为``激活函数''，一般为 $sigmoid$ 函数，其取值域为 $[0,1]$ ，其表达式为：
\begin{equation}
	f(x)=\frac{1}{1+e^{-x}}
\end{equation}
或者也可以是$tanh$函数，其取值域为 $[-1,1]$，其表达式为：
\begin{equation}
	f(x)=\frac{1-e^{-x}}{1+x^{-x}}
\end{equation}
这类函数糅合了线性和非线性特性函数，当 $x$ 较大时函数迅速收敛至值域的边界，当 $x$ 较小时函数是S型的非线性函数，相比于传统的阈值函数能更好的模拟神经元的工作原理。

在解码阶段，映射函数 $g(h)$ 将隐含层特征空间映射回重构的输入层$x$，表示为：
\begin{equation}
	\hat x=g(\hat{W}h+b_y)
\end{equation}	
其中，$g$是解码器的激活函数，若采用线性函数，则该解码器被称为``线性解码器''（Linear Decoder），若采用$sigmoid$ 函数，则是原型自动编码器采用的架构。训练自动编码器的过程是在训练样本集D上寻找$\theta=\{W,b_y,b_h\}$ 的最小化重构误差，重构误差的表达式为：
\begin{equation}
	J_{AE}=\sum_{x \in D}L(x,g(f(x)))
\end{equation}
其中，$L$为重构误差函数，一般可用平方误差函数或交叉熵损失函数，二者分别表示为：
\begin{equation}
	L(x,y)=||x-y||^2
\end{equation}
\begin{equation}
	L(x,y)=-\sum_{i=1}^{d_x}[x_ilogy_i+(1-x_i)log(1-y_i)]
\end{equation}
其中，平方误差用于线性$S_g$，交叉熵损失函数用于$sigmoid$\cite{17}。图\ref{fig:origAE}展示了原型自动编码器的结构。

\begin{figure}
\centering
\includegraphics[scale=0.3]{./Pictures/origAE.eps}
\caption{原型自动编码器，它由输入层、隐藏层和输出层构成。}
\label{fig:origAE}
\end{figure}

为了适应不同的条件，满足不同的任务需求，研究人员对原型自动编码器进行调整产生了大致4类自动编码器，分别是：基于稀疏理论的自动编码器、基于统计理论的自动编码器、基于鲁棒理论的自动编码器、基于卷积理论的自动编码器。

\section{基于稀疏理论的自动编码器}
基于稀疏理论的自动编码器对原型自动编码器的隐含层添加了约束条件并增加了隐含层数量，因而当隐含层神经元的数量很大时，该类自动编码器依然能发现输入数据的结构性特征。设x是给定神经网络输入，$\rho$是稀疏参数，$j$为所有隐含层神经元的平均激活值。为了达到约束每个神经元的目的，取$\rho_j=\rho$，一般的，$\rho$的取值在0附近。稀疏自动编码器在原型自动编码器的代价函数中增加了稀疏惩罚项，其表达式为：
\begin{equation}
	KL(\rho||\rho_j)=\rho \log \frac{\rho}{\rho_j} + (1-\rho)\log \frac{1-\rho}{1-\rho_j}
\end{equation}
此时的代价函数为：
\begin{equation}
	J_{sparse}(W,b)=J(W,b)+\beta \sum_{j=1}^{s_2}KL(\rho||\rho_j)
\end{equation}
其中，$\beta$表示稀疏惩罚项的权重\cite{24}。

基于稀疏理论的自动编码器是目前应用最为广泛的自动编码器。2013年，邓俊将给予稀疏理论的自动编码器用于特征转换和语义情感识别取得了良好的效果\cite{25}。马云龙将其用于数据流的异常检测\cite{26}，张开旭将其用于中文词汇特征提取\cite{27}。

基于稀疏理论的自动编码器能提取高维数据变量的稀疏解释性因子，保留原始输入的非零特征，增加表示算法的鲁棒性，增强数据的线性可分性，是分类边界变得更加清晰，并且能在一定程度上空盒子变量的规模，改变给定输入数据结构，丰富了原有信息，提高了信息表述的全面性和准确率。但由于原始数据分布稠密程度不同，经过信息解锁后的稀疏变量难以控制。另外KL 散度在惩罚激活值时需要预先给定稀疏目标的期望，并且该类自动编码器要求每个隐含层的稀疏程度基本一致，致使远零激活值的惩罚效果较差，欠拟合的问题时常出现。

\section{基于统计理论的自动编码器}
基于统计理论的自动编码器又叫降噪自动编码器，其核心思想是：编码器将含有一定统计特性的噪声（腐坏向量）加入输入数据，便于硬汉层对数据进行编码，保存输入数据中的信息，解码器根据噪声统计特性从未受到干扰的数据中估计出受干扰数据的原始数据的分布参数，从而消除背景噪声\cite{28}，该类自动编码器的代价函数为：
\begin{equation}
	J_{AE}=\sum_tE_q(\hat x|x^t)
\end{equation}
其中，$E_q(\hat x|x^t)$是输入噪声的期望，一般用高斯噪声作为腐坏向量，其表达式为：
\begin{equation}
	\hat x=x+\varepsilon,\varepsilon \sim N(0,\sigma^2I)
\end{equation}
其中，$\varepsilon$表示整个自动编码器的正规化程度。为了便于计算，又是可用二项随机隐藏噪声代替高斯噪声\cite{29}。降噪自动编码器的训练规则为重构对数似然函数：
\begin{equation}
	-\log P(x|c(\hat x))
\end{equation}
其中，$x$是未受到噪声干扰的输入数据，$\hat x$是腐坏向量，$c(\hat x)$ 是从$\hat x$中获取的数据编码。将对数似然函数用于该类的自动编码器的训练，能最大限度地利用无类标签数据，用未受到噪声干扰的数据将原始数据估计出来。

基于统计理论的自动编码器是一种经过正规化的自动编码器，其内部映射均具有鲁棒性，腐坏向量的加入有效降低了自动编码器对微小随机扰动的敏感性，缩小了重构误差，打破了训练数据必须在输入数据概率密度曲线附近的局限性\cite{30}。 因此，基于统计理论的自动编码器常被用于构建生成性模型，在区域自适应方面取得了良好的效果，为深度理论的发展打下了坚实的基础\cite{31}。但由于背景噪声的统计特性不同，其边缘分布对原始参数的估计过程有较大的影响，当原始输入是高维复杂函数时，重构误差显著增加。另外，该类自动编码器的计算效率极低，对硬件及软件的要求较高。目前，CPU的浮点运算和向量运算能力远不如GPU，GPU的硬件能够管理数千个并行线程而不需要开发人员进行任何编程。GPU拥有高速带宽的独立显存，适合处理并行重复计算任务，大幅度降低系统成本。Matlab的循环运算效率较低，程序封装性差，而Python 具有非常简洁而清晰的语法，适合完成各种高层任务，其动态反射语言不受操作系统的限制，可以在主流的Windows，Linux/Unix，Mac上面运行，并能面向对象编程，结合模式设计手段，能最大限度地满足系统设计变化需求。降噪自动编码器的设计原理如图\ref{fig:deAE}。
\begin{figure}
\centering
\includegraphics[scale=0.7]{./Pictures/deAE.eps}
\caption{降噪自动编码器的设计原理}
\label{fig:deAE}
\end{figure}

\section{基于鲁棒理论的自动编码器}
为了进一步提高表示学习算法的鲁棒性，研究人员在原型自动编码器的代价函数表达式中加入解析性收缩惩罚因子，以减少特征表示的自由度，使隐含层神经元达到饱和状态，进而将输出数据限制在参数空间的一定范围内。该惩罚因子实际上是编码器Jacobian矩阵的Frobenius范数，其作用是降低极小化变量对编码器的影响，辅助编码器学习数据特征。令$J(x)=\frac{\partial f_{\theta} (x)}{a}$，其中$x$ 是编码器Jacobian 矩阵的估计，收缩自动编码器的代价函数为：
\begin{equation}
	J_{CAE}=\sum_tL(x^t,g_{\theta}(f_{\theta}(x^t)))+\lambda ||J(x^t)||_F^t
\end{equation}
其中，$\lambda$是反映矩阵正规化程度的活跃参数。收缩自动编码器的传递函数为$sigmoid$函数，因此解析性收缩惩罚因子可表示为：
\begin{equation}
	||J(x^t)||^2=\sum_j(f_{\theta}(x)_j(1-f_{\theta}(x)_j))^2||W_j||^2
\end{equation}

由于解析惩罚因子的限制，基于鲁棒理论的自动编码器对输入数据中的小扰动敏感性较小，且重构特征不受惩罚因子影响，数据表示的准确率较高，便意神经网络计算代价函数。同时，活跃参数$\lambda$能够权衡代价函数的鲁棒性和重构误差，辅助BP 算法优化神经网络参数\cite{32}。 为了克服自动编码器的解析惩罚因子只对输入数据中的极小扰动具有鲁棒性的缺陷，研究人员利用统计理论对其代价函数提出进一步的修正，进而惩罚不同阶的偏差，使得代价函数变化为：
\begin{equation}
	J_{CAE+H}=\sum_t L(x^{(t)},g_{\theta}(x^{(t)}))+\lambda ||J(x^{(t)})||_F^2+\gamma E_{\varepsilon}[ ||J(x)-J(x+\varepsilon)||_F^2 ]
\end{equation}
其中，$\varepsilon : N(0,\sigma^2I)$，$\gamma$ 是关联性正规化活跃参数。

经过改进后，自动编码器的鲁棒性进一步得到提高，能出色地完成无监督特征转换热舞，深化了特征表示学习算法的算法研究\cite{33}。但是由于基于鲁棒理论的自动编码器原理相对复杂，构建、训练和调整的难度较大，因而针对该类自动编码器的研究相对较少。

\section{基于卷积理论的自动编码器}
上文中讨论的自动编码器均不能有效解决图像(2D)数据中的池化与白化问题，并且大量冗余参数被强制参与计算，使得计算效率较低，然而基于卷积理论的自动编码器是一种专门用于处理图像数据的神经网络，该结构利用重要的局部特征重构原始数据，且输入数据的所有局部特征共享权值矩阵，因而该类自动编码器的隐含层能完整保存受局部空间限制的边缘特征。

对于单通道的输入$x$其$k$阶特征映射的隐含表示是：
\begin{equation}
	h^k=\sigma(x*W^k+b^k)
\end{equation}
其中，$sigma$是激活函数，一般采用$sigmoid$函数，``*'' 表示2D卷积运算，$W^k$表示权值矩阵，$b^k$表示偏置向量，卷积运算表达式为：
\begin{equation}
	E(\theta)=\frac{\sum_{i=1}^{n}(x_i-y_i)^2}{2n}
\end{equation}
该类自动编码器的重构函数为：
\begin{equation}
	y=\sigma(\sum_{k \in H}h^k* \hat W^k+c)
\end{equation}
其中，$c$为每个数据通道的偏置，$H$是隐含特征映射集，$\hat W$是权值矩阵的批处理，权值更新的规则为随机梯度下降\cite{34}。值得注意的是，在该类自动编码器中，一个隐含映射对应一个偏置值，偏置向量$b$对整个映射均有效，并且，每个映射负责捕捉数据的一个特征，便于对神经网络进行预训练和调优，有效缩短了特征提取的时间，简化了特征提取的过程，实现了数据特征的分层提取，卷积自动编码器原理如图\ref{fig:conAE}。

\begin{figure}
\centering
\includegraphics[scale=0.7]{./Pictures/conAE.eps}
\caption{卷积自动编码器的设计原理}
\label{fig:conAE}
\end{figure}

基于卷积理论的自动编码器用基本影像块的线性组合来拟合原有图像，显著提升了图像识别的速度和准确率。目前，该类自动编码器已成功完成目标辨识、动态跟随和视觉模拟等任务，有效解决了原有自动编码器处理图像数据是出现的识别速度慢，准确率低，需要大量类表数据等问题\cite{8}。但是，由于理论和结构的一些不足，每个隐含层的输出都受到极大的限制，因而对预训练的依赖性很强，需要反复迭代，训练时间及其漫长（一般为几周甚至几千小时）。另外，节点分布方式对图像识别的效果影响较大，但没有具体的理论指出节点分布具体如何影响训练结果，且该类自动编码器的构建和训练需要很多技巧，操作性较差。

\chapter{系统构建工具库}

\section{Python开发框架}
Theano是Python中重要的第三方开发库，它与numpy能高效处理计算矩阵和向量。Theano可以抽象表达计算公式，然后被Theano 的C编译器和GPU编译器编译成动态加载模块。Theano 能高效稳定地优化图像抽象执行与计算。Theano支持图像的动态差分和GPU 运算。Theano提供的功能足以满足先进的深度学习算法（包括了卷积算法），并能高效执行。

(1) \textbf{与numpy紧密结合：} 能直接接受numpy.ndarray 类型数据输入，输出，并用于内部CPU计算。

(2) \textbf{自动设置使用GPU：}能抽象的表示图像计算模型，所以用户无需考虑是否使用GPU参与计算，用户只需要在theano 框架中配置GPU参数选项，让theano框架自动分配计算任务给CPU和GPU（GPU的矩阵运算比CPU快140倍）。

(3) \textbf{符号微分：}Theano能自动导出表达式的梯度计算式，它极大方便了梯度学习算法的代码表示。

(4) \textbf{速度和稳定性的优化：}在生成字节码之前，Theano能重新排列并优化用户的计算式，它会将你的计算公式转换成范式，难以计算的函数会（例如：$\log(1+x)$）被转换成多项式模型，并对其一些特殊情况进行速度优化。

(5) \textbf{动态生成C代码：} Theano中提供的许多表达式都有对应的Python实现和C实现。这些C代码被特殊优化，能异常快速的计算，其缓存系统避免了冗余的再次编译。

(6) \textbf{丰富的特使和验证手段：}Theano中包含数以千计的单元测试样例，它们能快速检测计算过程中引入的回归误差。Theano 同时也包含自我验证执行模式，以检测和诊断许多种的内部计算误差。

\section{Caffe开发框架}
Caffe \footnote{http://caffe.berkeleyvision.org/}是一个清晰而高效的深度学习框架，其作者是博士毕业于UC Berkeley 的贾扬清\footnote{http://daggerfs.com/}，他目前在Google工作。Caffe是纯粹的C++/CUDA架构，支持命令行、Python和MATLAB接口；可以在CPU和GPU直接无缝切换。Caffe的优势：	

(1) \textbf{上手快：}模型与相应优参数化都是通过配置文件设置，而非在实现代码中给出。Caffe给出了模型的定义、最优化设置以及预训练的权重，方便立即上手。

(2) \textbf{速度快：}能够出色承担实验研究和商业产品部署。Caffe与cuDNN结合使用，测试AlexNet模型，在K40上处理每张图片只需要1.17ms，说明这是迄今为止最快的运算框架。

(3) \textbf{模块化与开源化：}在它被开发的第一年中，来自全世界超过1,000开发者为期优化工作做出了贡献。由于这些优质的代码，我们才能实现最佳的模型设计和代码的高效执行。

(4) \textbf{社区开发维护：}Caffe已经成为学术研究项目和商业开发模型，甚至大规模的视觉、语音、多媒体的主要参考模型。Github上有其开发社区。

\section{Matlab开发框架}
Rasmusberg Palm学者开发了对应的深度学习的Matlab开发框架\cite{IMM2012-06284}（DeepLearnToolbox\footnote{https://github.com/rasmusbergpalm/DeepLearnToolbox}），并在github上进行开源。其主要功能包括：
\begin{enumerate}
	\item\textbf{深度信念网络模型}；
	\item\textbf{堆叠自动编码器模型}；
	\item\textbf{卷积神经网络模型}；
	\item\textbf{卷积自动编码器模型}；
	\item\textbf{简单神经网络模型}。
\end{enumerate}


\chapter{总结与展望}
\section{深度理论方面}
\begin{enumerate}
	\item 无监督逐层贪心预训练只是在一定程度上解决了局部最小问题，随着隐含层个数、神经元数量和书籍复杂程度的增加，梯度稀释越发严重，现有方法依然不能遏制局部最小。基于梯度理论的随机初始化往往不能达到预期效果，使自动编码器不能拟合一些高维复杂函数，但没有文献指出其原因\cite{35}。
	\item 自动编码器的研究有时需要结合计算机技术和统计理论，相应的神经生理科学发展缓慢，未能及时指导自动编码器的深入研究\cite{36,37}，使得自动编码器的发展陷入困境。
	\item 自动编码器的训练及其繁琐，先要用无监督逐层贪心预训练算法对隐含层逐层训练，达到一定程度后才能使用BP 算法、牛顿算法、共轭梯度法、或SDBP算法对整个神经网络的参数进行系统性优化调整，时间长，误差大，需要很多技巧，且学习到的知识表示的物理意义不明确。		
\end{enumerate}

另外，现有的自动编码器都是由不同类型的建模单元堆叠而成，这些建模单元均有理论缺陷，因而由它们构建的深度结构必然不完善。综上所述，完善深度学习理论，彻底搞清梯度理论与神经网络初始化的关系，找到能将逐层预训练与系统性参数优化结合的算法，并开发出新的建模单元和功能更加强大的深度结构，最终把各层学习到的知识表示成有物理意义的知识是自动编码器理论创新的要求。

\section{建模策略方面}
\begin{enumerate}
	\item 自动编码器产生以后，神经网络的研究进入了崭新的阶段，但在以往的研究中没有文献说明设计神经网络时，层数与节点数分布关系和权值分享对不同类型自动编码器造成何种影响\cite{38,39}。
	\item 随着神经网络的隐含层数量和节点数的持续增加，目前的建模方法（堆叠、预训练、调优）相对单一，不能满足用户日益提高的要求\cite{40}。
	\item 现有的预训练算法和系统性参数优化策略对类标签数据集有较强的依赖性，远没有达到``真正意义上的无监督\cite{41}''，并且没有文献指出二者以何种比例搭配能辅助训练，也没有文献讨论不同类型代价函数等指标造成何种影响。随着今后研究的深入，搞清节点分布、隐含层数量和权值分享方式与不同类型自动编码器间的关系，提高无类标数据的利用率，用模块拼装的方法建立深度结构，将不同类型自动编码器单元引入同一个神经网络，实现自动编码器的多样化和模块化是自动编码器建模策略变革的必然趋势。
\end{enumerate}

\section{工程实践方面}
\begin{enumerate}
	\item 自动编码器 处理的数据规模大，结构复杂，现有的软件和硬件难以满足用户需求。
	\item 不同类型的自动编码器原理不同，结构不一，现有的自动编码器不具有任务针对性，效率和准确率也迥然不同\cite{42}。
	\item 自动编码器的研究与应用跟传统神经网络相比有很大的差异，因而相对独立。在以后的工程实践中，提高现有软件的数据处理能力和硬件的运算能力，开发针对深度结构的芯片和软件，快速实现大规模高维数据的分层特征提取，验证自动编码器的性能\cite{43}，并根据不同类型的自动编码器的特点构建神经网络完成相关任务，实现特定任务与特定种类的自动编码器的对应，将自动编码器与传统神经网络结构有机结合，实现多种神经网络间的功能互补与强化是自动编码器应用实践的必经之路。
\end{enumerate}
\backmatter
\ZJUthesisbib{thesisbib}
\ZJUindex
\end{document}






