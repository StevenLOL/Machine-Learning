\documentclass[oneside]{ZJUthesis}

\hypersetup{colorlinks=false}
\begin{document}
\songti
\title{自动编码器的研究与展望}
\author{姜楠}
\supervisor{龙胜春~副教授}
\major{计算机科学与技术+自动化1101}
\institute{计算机科学与技术学院}
\submitdate{2015年~2月}

\makeCoverPage

\mainmatter
\maketitle
\textbf{摘 要：}深度学习开创了机器学习领域发展的新纪元，它是神经网络模型的一个重要分支。自动编码器模型是深度学习领域中最重要的三大模型之一，是一种无监督学习算法，他能完成非线性特征提取，不需要标注的数据集。在本文中，我们首先阐述了自动编码器在历史发展中的演进，接下来我们介绍原型自动编码器的原理和架构，进而介绍它的训练学习特征的方法、步骤。然后，我们又介绍了自动编码器的变种，例如：稀疏自动编码器，卷积自动编码器。最后，我们探讨了自动编码器理论在实践中遇到的障碍，并分析了它的未来发展趋势。

\textbf{关键词：}{自动编码器~稀疏编码~无监督学习~神经网络}
\chapter{引言}
监督学习（supervised learning）在许多领域有很成功的应用，如车牌识别、人脸识别、语音识别、自动驾驶等。尽管如此，监督学习还是有很大的限制。因为监督学习需要手工的选择特征来训练算法。提取的特征质量直接影响到机器学习算法的性能。虽然很多权威学者针对特定的应用提出了很多有效的特征，但这些算法技巧不具有推广的意义。BP神经网络模型由输入层、隐藏层、输出层构成，是监督学习算法中的一个广泛使用的模型。通过求解误差的偏导，并利用反向传导公式迭代求解出系统的极值，从而学习出数据集中的`` 合理规则''。特别地，他能突破传统多项式公式有限的拟合数据的能力，能学习到更加复杂的非线性函数规律和即使数据中包含一些误差，他也能收敛致最优解，拥有较强的自适应性。然而，由于BP神经网络的代价函数不是严格意义上的凸函数，一旦算法在迭代优化过程中陷入局部极值，就有可能无法求得系统的最优解。若要拟合高维复杂的函数，采用较复杂的神经网络模型就会导致函数运算量巨大、收敛过慢，若采用较小的神经网络模型，则只能学习到简单的函数方程，可能会忽略了重要的信息特征\cite{1}。

然而在实际应用中，我们无法预先知道样本的标签，只能从原始的无标签的样本集开始，进行分类器的设计，即通常所说的无监督学习方法（unsupervised learning）。无监督学习方法可以分类两类，一类为基于概率密度函数估计的方法，它试图找出数据集在特征空间的分布参数，再用特征空间分布进行分类处理，例如稀疏编码算法。另一类称为基于样本间的相似性度量的聚类方法，它通过聚类方法将样本划分成不同类别。 稀疏编码算法是第一类无监督算法的重要实践，它将原始信号表示为字典元素的一个线性组合：$x=D*a$，我们用 $x$ 表示原始信号， $D$ 为我们得到的字典（dictionary），通过字典 $D$ ， 原始信号 $x$ 能被完备地表示为 $a$ 的线性组合。当我们将稀疏性概念引入后，即我们希望 $a$ 是稀疏的，只有较少的非零项，这样做最突出的优点是运算速度能有效提升，因为Matlab只对非零元素进行操作。另一方面，为了解决字典 $D$ 的退化（degeneracy）问题，Hinton等人提出了稀疏自编码（Sparse Auto-encoder）学习算法。稀疏自编码算法是一种自动提取样本（如图像）特征的方法，它把原始数据用隐藏层的特征空间向量表示，再把隐藏层特征解码成重构的输出层。这样，隐藏层中的特征信息就是输入层的一个压缩表示，而且有效减少了冗余信息。并且，压缩表示的特征很适合进一步用作分类器的输入集。该模型可以用来标注无标签的数据集，免去了繁复的人工打标签的操作，同时也能有效降低输入数据的维度，防止出现``维度灾难''。

第一节介绍了自动编码器模型的历史发展过程，第二节介绍了原型自动编码器和后来演绎变形的各种自动编码器的数学模型和建模机理，包括：稀疏自动编码器、统计自动编码器、收缩自动编码器和卷积自动编码器。第三节，我们介绍常用的构建深度学习的开源库，最后我们分析了自动编码器目前在实践中遇到的问题，并进一步明确它的发展方向。


\chapter{自动编码器和稀疏编码的历史发展}
\begin{enumerate}
     \item 1959年，David Hubel等人\cite{44}在神经实验中，研究猫的视觉条纹皮层简单细胞，得出一个惊人的结论：主视皮层V1区神经元能将视觉信息转化为`` 稀疏表示''的特征，自此提出机器学习领域重要的`` 稀疏表示''的概念。
    \item 1972年，Barlow\cite{47}推导演绎出，自然环境的统计模型和稀疏性（Sparsity）必然存在某种联系，即稀疏表示可以体现出在大脑中的统计特征。
    \item 1986年，Rumelhart提出了自动编码器（Auto-encoder）的概念模型，并将此模型用于处理高维复杂数据，展示其模型的性能和优势\cite{3}。
    \item 1987年，Field等人\cite{48}提出，主视皮层V1 区细胞在学习视网膜的图像结构后能产生图像的稀疏表示。1989 年，D.J.Field等人\cite{50}提出了稀疏编码方法，它能使只有少数神经细胞响应任意的信号输入。
    \item 1997年，B.A.Olshausen和D.J.Field\cite{52} 按照集合的完备性的理论，提出了``超完备''的稀疏编码算法。
    \item 1997年，Bell和Sejnowski\cite{53}利用独立分量分析算法（Independent Component Analysis）分析自然图像，发现独立分量算法也能产生稀疏编码的特征。
    \item 2006年，Hinton和他的学生Ruslan Salakhutdinov\cite{2}修正了原型自动编码器的模型结构，并称其为深度自动编码器。先用无监督学习算法，逐层贪心训练单层的自动编码器，最后针对整个深度自动编码器，用反向传播算法进行系统的参数调优，这样的训练手段显著降低了神经网络的训练时间，同时也能有效防止传统反向传播方法极易陷入局部极值的情况。
    \item 2007年，Benjio分层贪心训练受限玻尔兹曼机，再集中调优深度信念网络，取得了历史最佳的分类精度\cite{4}。
    \item 2008年，Vincent改进了自动编码器模型，在输入层添加高斯白噪声，获得了降噪自动编码器，它能有效降低系统的过拟合现象，具备更好的鲁棒性和良好的分类精度\cite{5}。
    \item 2009年，Benjio等人在文章``Learning Deep Architectures for AI''中总结了RBMs，SAE，CNN等已有的深度结构，并分析了在不同情况下的系统特性\cite{6}。
    \item 2010年，salah等人在文章``Contractive Auto-Encoders：Explicit Invariance During Feature Extraction'' 中，通过对系统的代价函数中添加Frobenius范数的惩罚因子，对自动编码器的解码和编码过程加以限制，提出了收缩自动编码器，获得了类似于降噪自动编码器、约束自动编码器的实验效果\cite{7}。
    \item 2011年，Lugano和Switzerland在文章``Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction''中，将卷积神经网络架构引入自动编码器模型，同时消去了不必要的约束惩罚项，利用其单层卷积自动编码器构建的深层卷积神经网络实现了在权威数据集上的突破性成果\cite{8}。
    \item 2012年，Pierre Baldi等人从数学角度，分析线性自动编码器并推导出非线性自动编码器。同时，也分析了自动编码器与无监督学习之间的联系\cite{9}。
    \item 2012年，Bengio等人比较了原型自动编码器、稀疏自动编码器、卷积自动编码器、收缩自动编码器、降噪自动编码器和限制玻尔兹曼机等结构的在不同参数配置和实验验数据集上的性能表现。\cite{10,11,12,13,14}。
    \item 2013年，Telmo Amaral在文章``Using Different Cost Functions to Train Stacked Auto-encoders'' 中，比较在训练过程中使用不同的代价函数，并评价分析这些代价函数对特征学习的影响，指出了优化代价函数的研究方向\cite{15}。
\end{enumerate}

\chapter{数学模型及数学原理}
\section{原型自动编码器}
通过无监督学习训练，原型自动编码器能学习到数据中的非线性特征结构，他能提取出高位复杂的输入数据中的低维特征，将此特征用于深度学习其他模型的输入，能有效提升系统的精确度\cite{16}。

自动编码器模型包括编码和解码两个主要步骤。在编码阶段，编码器将输入数据 $x$ 映射到隐含层特征$h$，其映射函数为：
\begin{equation}
	h=f(Wx+b)
\end{equation}
其中，$f$被称为``激活函数''，一般为 $sigmoid$ 函数，其取值域为 $[0,1]$ ，其表达式为：
\begin{equation}
	f(x)=\frac{1}{1+e^{-x}}
\end{equation}
或者也可以是$tanh$函数，其取值域为 $[-1,1]$，其表达式为：
\begin{equation}
	f(x)=\frac{1-e^{-x}}{1+e^{-x}}
\end{equation}
这类函数糅合了线性和非线性特性函数，当 $x$ 较大时函数迅速收敛至值域的边界，当 $x$ 较小时函数是S型的非线性函数，相比于传统的阈值函数能更好的模拟神经元的工作原理。

在解码阶段，映射函数 $g(h)$ 将隐含层特征空间映射回重构的输入层$\hat x$ ，表示为：
\begin{equation}
	\hat x=g(\hat{W}h+\hat b)
\end{equation}	
其中， $g$ 是解码器的激活函数，若采用线性函数，则该解码器被称为``线性解码器''（Linear Decoder），若采用$sigmoid$ 函数，则是原型自动编码器采用的架构。在训练自动编码器的过程中，我们利用迭代求解当前状态的梯度值，最终求得在训练样本集 $D$ 上的一组最佳的参数配置 $\theta=\{W,\hat W,b,\hat b\}$ ，使系统的重构误差函数最小，重构误差函数的表达式为：
\begin{equation}
	J_{AE}=\sum_{x_i \in D}L(x_i,g(f(x_i)))
\end{equation}
其中， $L$ 为每个输入项 $x_i$ 的重构误差值，一般地，我们使用平方误差函数或者交叉熵损失函数表示，二者数学公式分别表示为：
\begin{equation}\begin{array}{l}
	L(x,y)=\sum_{x_i \in D}\|x-\hat x\|^2  \\
    L(x,y)=-\sum_{x_i \in D}[x_i \log \hat x_i+(1-x_i)\log(1-\hat x_i)]
\end{array}\end{equation}
其中，当我们采用$g$为线性函数时，系统的重构误差函数须采用平方误差函数。当我们采用$g$为 sigmoid函数时，系统的重构误差函数须采用交叉熵损失函数，这两者之间相互一一对应 \cite{17}。 图\ref{fig:origAE} 展示了原型自动编码器的结构。原型自动编码器包含输入层、隐藏层和输出层，其中编码过程对应于输入层到隐藏层的映射，解码过程对应于隐藏层到输出层的映射。

\begin{figure}
\centering
\includegraphics[scale=0.4]{./Pictures/origAE.eps}
\caption{原型自动编码器，它由输入层、隐藏层和输出层构成。}
\label{fig:origAE}
\end{figure}

简洁的自动编码器模型在运用到实际条件中，演变产生各种修正的模型，按照其主要类别，大致分为：稀疏自动编码器、降噪自动编码器、鲁棒自动编码器和卷积自动编码器。


\section{稀疏自动编码器}
对稀疏性的兴趣源自于新的抽样理论-压缩传感（compressed sensing）的发展，当我们用压缩形式表示输入信号，我们能更方便的对信号进行加工处理，如压缩、编码等。通过对原型自动编码器的隐藏层添加约束条件，并增加隐藏层节点个数，我们能在隐藏层中获得原始数据的结构性特征。假设自定编码器的输入为$x$，我们的约束项为$\rho$，隐藏层神经元节点的平均激活度记作$\rho_j$。一般地，我们期望我们隐藏层的绝大多数神经元的取值在0 附近，少数神经元节点取值接近1，即只有少数神经节点处于激活状态。我们期望$\rho$取值在0附近（例如，0.05），同时令$\frac{1}{m}\sum_j^m{\rho_j}=\rho$。在稀疏自动编码器中，我们在模型的代价函数中增加稀疏惩罚项$KL(\rho||\rho_j)$，其表达式为：
\begin{equation}
	KL(\rho||\rho_j)=\rho \log \frac{\rho}{\rho_j} + (1-\rho)\log \frac{1-\rho}{1-\rho_j}
\end{equation}
此时，系统的代价函数为：
\begin{equation}
	J_{SAE}(W,b)=J(W,b)+\beta \sum_{j=1}^{s_2}KL(\rho||\rho_j)
\end{equation}
其中，$J_{SAE}(W,b)$代表稀疏自动编码器的代价函数，$J(W,b)$代表原型自动编码器的代价函数，$\beta$表示稀疏惩罚项的权重，$s_2$代表隐藏层节点个数\cite{24}。

2013年，邓俊等人在语义检测和情感识别领域利用稀疏自动编码器取得了良好的实验效果\cite{25}。同年，马云龙等人利用训练的稀疏编码器用在数据流的异常检测领域\cite{26}。在自然语言处理领域，张开旭等人利用稀疏编码器提取中文词汇的特征\cite{27}。 基于稀疏理论的自动编码器，在各个研究领域获得了广泛的应用。

稀疏自动编码器能提取高位数据中的稀疏性特征，增加数据的线性可分性。然而原始数据分布规律不同，故我们需要较大的数据集来训练稀疏自动编码器以便完成的获取稀疏特征变量。另外我们需要预先调节KL散度的惩罚值，并要求隐藏层的平均激活程度相同，致使实习的效果较差，容易出现欠拟合问题。

\section{降噪自动编码器}
降噪自动编码器（Denoising Auto-encoder）是在自动编码器的输入层中加入高斯分布的随机噪声，进而自动编码器在训练过程中，尝试学习去除这种噪声，解码过程中，模型根据噪声统计特性，从未受到干扰的数据中，估计出原始数据的分布规律，从而消除添加的高斯噪声。最终，自动编码器学习到的特征具有更强的鲁棒性，拥有更强的泛化能力\cite{28}，降噪自动编码器的代价函数为：
\begin{equation}
	J_{DAE}=\sum_t{E_q(\hat x|x^t)}
\end{equation}
其中，$E_q(\hat x|x^t)$是输入高斯噪声的期望，其表达式为：
\begin{equation}
	\hat x=x+\varepsilon,\varepsilon \sim N(0,\sigma^2I)
\end{equation}
其中，$\varepsilon$代表正则化因子。由于高速随机噪声计算复杂，我们采用二项随机隐藏噪声作为替代\cite{29}。在降噪自动编码器的训练过程中，我们利用拉格朗日方法求解对数似然函数：
\begin{equation}
	-\log P(x|c(\hat x))
\end{equation}
其中，$x$是未受到噪声干扰的输入数据，$\hat x$是添加噪声后的向量，$c(\hat x)$ 是从$\hat x$中获取的特征向量。利用对数似然函数，我们能求解模型的极值，最大限度地获取无标签数据的特征向量。其系统结构图展示在图\ref{fig:deAE}。
\begin{figure}
\centering
\includegraphics[scale=0.7]{./Pictures/deAE.eps}
\caption{降噪自动编码器的设计原理}
\label{fig:deAE}
\end{figure}

降噪自动编码器经过正则化因子的约束，使得映射到的特征空间更具有鲁棒性，高斯噪声添加至输入数据能有效降低自动编码器模型对随机的微小扰动产生的误差，有效降低了系统的敏感度，打破了原有数据概率密度曲线的限制\cite{30}。考虑到降噪自动编码器拥有较强的自适应能力，Q. You 等人将此理论用于构建生成模型（Generative Model）\cite{31}。

若原始输入是高维复杂函数，我们若添加背景噪声，会使得重构误差显著增加，不利于系统收敛至最优解。另外，由于模型足够复杂，需要采用高成本的硬件环境，若能采用CPU并行运算，能大幅度降低运算成本。

\section{收缩自动编码器}
为了进一步约束特征空间的输出数据，减少特征表示的自由度，研究员在自动编码器的代价函数中添加解析性收缩惩罚因子，即Frobenius范数。其数学定义为：
\begin{equation}
\|A\|_F=\sqrt{\sum_{ij}{|A_{ij}|^2}}=\sqrt{Tr(AA^H)}
\end{equation}
它能降低输入数据的扰动对自定编码器的影响。令$J(x)=\frac{\partial f_{\theta} (x)}{a}$，其中$x$ 代表了自动编码器 Jacobian 矩阵，收缩自动编码器（Contractive Auto-encoder）的代价函数为：
\begin{equation}
	J_{CAE}=\sum_tL(x^t,g_{\theta}(f_{\theta}(x^t)))+\lambda ||J(x^t)||_F^t
\end{equation}
其中，$\lambda$是正则化因子，负责权衡重构误差和惩罚因子对系统的代价函数的贡献。收缩自动编码器在编码（$f_{\theta}(x)$）和解码（$g_{\theta}(x)$）阶段均使用 $sigmoid$ 函数。其惩罚因子可表示为：
\begin{equation}
	||J(x^t)||^2=\sum_j(f_{\theta}(x)_j(1-f_{\theta}(x)_j))^2||W_j||^2
\end{equation}


当我们添加Frobenius范数作为惩罚因子后，收缩自动编码器能有效处理输入数据中的小扰动，而且隐藏层重构特征不受惩罚因子约束，有效提高了数据表示的鲁棒特性。我们可以利用BP算法求解系统的最优解，获得系统的最佳配置参数\cite{32}。

由于收缩自动编码器的惩罚因子只对输入数据中的微小扰动具有鲁棒性，对其进一步修正的模型为：
\begin{equation}
	J_{CAE+H}=\sum_t L(x^{(t)},g_{\theta}(x^{(t)}))+\lambda \|J(x^{(t)})\|_F^2+\gamma E_{\varepsilon}[ ||J(x)-J(x+\varepsilon)||_F^2 ]
\end{equation}
其中，$\varepsilon ~ N(0,\sigma^2I)$，$\gamma$ 是正规化因子。

经过进一步改进后，收缩自动编码器获得了更好的自适应性\cite{33}。但由于收缩自动编码器原理复杂，训练难度较大，目前针对该领域的研究尚未充足。


\section{卷积自动编码器}
在计算机图像处理领域，卷积自动编码器能有效解决图像中存在的池化和白化问题。上述讨论的模型在应用到图形图像领域后，需要配置大量冗余的参数，计算效率也大大降低。然而卷积自动编码器能获取局部特征，完整保留边缘特征。

对于输入是灰度图像$x$，其$k$阶映射后的特征是：
\begin{equation}
	h^k=\sigma(x*W^k+b^k)
\end{equation}
其中，$\sigma$采用$sigmoid$函数，``*'' 表示卷积运算操作，$W^k$表示权值$W$的$k$阶矩阵，$b^k$表示偏置的$k$阶向量，离散域的卷积运算的公式为：
\begin{equation}
	E(\theta)=\frac{\sum_{i=1}^{n}(x_i-y_i)^2}{2n}
\end{equation}
在解码阶段，其对应的重构方程为：
\begin{equation}
	y=\sigma(\sum_{k \in H}h^k* \hat W^k+c)
\end{equation}
其中，$c$表示各个数据通道的偏置项量，$\hat W$表示权值$W$的$k$阶矩阵，$H$是隐含层的特征集合，我们采用随机梯度下降法（Stochastic gradient descent）来求解模型的最优参数配置\cite{34}。卷积自动编码器能有效缩短特征提取时间，简化特征求解过程，卷积自动编码器的结构模型如图\ref{fig:conAE}所示。
\begin{figure}
\centering
\includegraphics[scale=0.7]{./Pictures/conAE.eps}
\caption{卷积自动编码器的设计原理}
\label{fig:conAE}
\end{figure}

卷积自动编码器能高效完成目标识别、目标动态跟踪能任务\cite{8}。然而，其对于训练严重依赖，需要很多遍迭代次数来求解配置参数，导致训练时间急剧上升（一般需要几周或者几千小时）。且该类模型的构建和训练步骤需要很多设计技巧，实验意义较差。


\chapter{系统构建工具库}
\section{Python开发框架}
Python语法简洁，结合设计模式手段，能高效完成高层任务，其动态反射语言能在Windows，Linux/Unix，Mac上编译运行。Theano\footnote{Theano official Website: deeplearning.net/software/theano/}是 Python 中重要的第三方开发库，它与numpy能高效处理矩阵和向量的运算。Theano 还提供了C编译器和GPU编译器，能将用户的抽象公式编成范式，并行地进行科学计算。同时，theano 能自动设置使用 GPU 框架，无需用户配置相关参数（GPU的矩阵运算比CPU快140倍）。另外，Theano框架中包含了上千个测试样例，能帮助用户诊断出代码中的 Bug 。

\section{Caffe开发框架}
Caffe \footnote{Caffe Official Website: caffe.berkeleyvision.org/}由 UC Berkeley 的贾扬清博士\footnote{Author: daggerfs.com/} 完成。Caffe全部由C++/CUDA搭建，它还对 Matlab 和 Python 提供开发接口，主要特点是其速度优势。其代码的模块化设计模式和代码开源化，对其自身的改进起到了关键作用。

\section{Matlab开发框架}
Rasmusberg Palm学者开发DeepLearnToolbox\footnote{Matlab Toolbox: github.com/rasmusbergpalm/DeepLearnToolbox}，并在github上进行开源，由众多人员进行维护\cite{IMM2012-06284}。它提供了集成的主流深度学习模型的代码框架，例如：深度信念网络、卷积神经网络。


\chapter{总结与展望}
1. 随着模型的架构变得巨大和神经元节点数量地增加，梯度弥散现象越来越严重，使得自动编码器无法拟合一些高维复杂函数\cite{35}。 另一方面，生物神经学科发展远远落后于深度学习发展速度，现有理论的突破需要神经科学的进一步研究成果\cite{36,37}。自动编码器的训练时间过长，系统调优需要很多设计技巧，且研究员尚无法认识学习到的特征的物理意义何在。另外，由于现有建模单元尚存在理论缺陷，简单堆叠搭建深度结构必然存在先天缺陷。目前的建模手段（堆叠、预训练、调优）相对单一，无法满足复杂网络训练需求\cite{40}。

2. 现有的预训练算法对类标签数据集有较强的依赖性，远没有达到``无监督学习''\cite{41}。不仅如此，现有算法对硬件需求极高，随着处理数据规模的增大，现有软硬件环境无法满足其需求。若能按照深度结构模型设计对应的硬件配置，那将革新现有的算法效率\cite{43}。

\backmatter
\ZJUthesisbib{thesisbib}
\ZJUindex
\end{document}






